{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding external features to our dataset:\n",
    "\n",
    "In this noteboook what we are going to do is add features that, according to the factory affect demand. Now, it is important to remember that our data corresponds to the orders made by the store to the factory, and not sales, hence features like weather or events may explain sales behaviour, however if the stores are not taking that information into account, then our time-series of orders would not be affected by these features.\n",
    "\n",
    "Nonetheless, the factory has suggested us that stores take into account these features. Lets see...\n",
    "\n",
    "The features that we will be adding are:\n",
    "- Football matches: currently we are only taking into account La Liga matches, however it would be idea to extend it to Champions, Euro Cup and World Cup (and to other sports such as tennis, and olympic games).\n",
    "\n",
    "- Festivities (public holidays).\n",
    "\n",
    "\n",
    "Other datasets that would be interesting to add would be:\n",
    "\n",
    "- Weather: Historical predictions for the following 7 days (if accurate), not historical weather.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Index\n",
    "\n",
    "<a href='#a1'>1. Matches</a>\n",
    "\n",
    "<a href='#a2'>2. Festivities</a>\n",
    "\n",
    "<a href='#a3'>3. Adding it all to the transactions dataframe</a>\n",
    "\n",
    "<a href='#a31'>3.1. Adding Public holidays</a>\n",
    "\n",
    "<a href='#a32'>3.2. Adding matches</a>\n",
    "\n",
    "<a href='#a4'>4. Cleaning NaN created</a>\n",
    "\n",
    "<a href='#a5'>5. Tests results & Save to file</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matches<a id='a1'></a>\n",
    "\n",
    "We have several teams in the Comunidad de Madrid, that will predictably have a different impact in our sales.\n",
    "\n",
    "Based on their impact, we agreed to divide the teams in four categories:\n",
    "\n",
    "* Real Madrid\n",
    "* Ath Madrid\n",
    "* Other from Comunidad de Madrid\n",
    "* Rest\n",
    "\n",
    "Based on this categorization, we have 8 different basic scenarios:\n",
    "\n",
    "* RM -AM\n",
    "* RM - Other Madrid\n",
    "* RM - Rest\n",
    "* AM - Other Madrid\n",
    "* AM - Rest\n",
    "* Other Madrid - Other Madrid\n",
    "* Other Madrid - Rest\n",
    "* Rest - Rest\n",
    "\n",
    "\n",
    "Lets now create manually a label enconder to take into consideration these 8 scenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic paths\n",
    "base_path = '../data/_auxiliary_data/'\n",
    "matches_file_name = 'MATCHES_2013-2019.xlsx'\n",
    "festivities_file_name = 'festivities_calendar_Madrid_2013-2020.csv'\n",
    "input_path = \"../data/03_processed/\" + \"1_filtered_transactions_clean.csv\"\n",
    "filtered_file_name=\"c1-filtered_transactions.csv\"\n",
    "sep=\";\"\n",
    "exit_path = \"../data/03_processed/\" + \"2_time_series.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div</th>\n",
       "      <th>date</th>\n",
       "      <th>hometeam</th>\n",
       "      <th>awayteam</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>matches_madrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP1</td>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Celta</td>\n",
       "      <td>Malaga</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP1</td>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Mallorca</td>\n",
       "      <td>Espanol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP1</td>\n",
       "      <td>2012-08-18</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Getafe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP1</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>Betis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP1</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   div       date    hometeam  awayteam  home  away  matches_madrid\n",
       "0  SP1 2012-08-18       Celta    Malaga     0     0               0\n",
       "1  SP1 2012-08-18    Mallorca   Espanol     0     0               0\n",
       "2  SP1 2012-08-18     Sevilla    Getafe     0     1               1\n",
       "3  SP1 2012-08-19  Ath Bilbao     Betis     0     0               0\n",
       "4  SP1 2012-08-19   Barcelona  Sociedad     0     0               0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read matches\n",
    "matches = pd.read_excel(base_path+matches_file_name,parse_dates = ['Date'] )\n",
    "matches.columns =  [col.lower() for col in matches.columns]\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify that the team names are normalized (one team - one name):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"hometeam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"awayteam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct_label_encod(team):   \n",
    "    \"\"\"Given a team name, returns 4 if real madrid, 2 if atletico, or 0 if other \"\"\"\n",
    "    if team=='Real Madrid':\n",
    "        return 4\n",
    "    elif team=='Ath Madrid':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Calculates the lable encoder described before:\n",
    "matches['label_encoder']=(matches['home'] +\n",
    "                                   matches['away'] +\n",
    "                                   matches['hometeam'].apply(funct_label_encod) + \n",
    "                                   matches['awayteam'].apply(funct_label_encod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[matches['label_encoder']>0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woops, we actually didn't take into account that we needed to aggregate the data in order to have a unique value per day. \n",
    "\n",
    "Nonetheless, what we can do to fix the issue of having too many lables is using as weights. Lets modify the previous function to give the same weight to Real Madrid and Atletico de Madrid.\n",
    "\n",
    "Note: in order to prove that both Real Madrid and Atletico de Madrid have the same impact, we would need to do a full analysis, however due to time constrains we can consider them as equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_of_team (team):   \n",
    "    \"\"\"Given a team name, returns 3 if real madrid or Atletico \"\"\"\n",
    "    if team=='Real Madrid' or team=='Ath Madrid' :\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Calculates the lable encoder described before:\n",
    "matches['weight']=(matches['home'] +\n",
    "                                   matches['away'] +\n",
    "                                   matches['hometeam'].apply(funct_label_encod) + \n",
    "                                   matches['awayteam'].apply(funct_label_encod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = matches.groupby(['date'])['weight'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now filter to only keep values greater than 0 (for performance purpose when merging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets only include days with at least one point of weight:\n",
    "df_matches = df_matches[df_matches['weight']>0][['date','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing variables\n",
    "\n",
    "validator_num_matches = df_matches[(df_matches['date']<= '2019-09-30') & (df_matches['date']>= '2008-01-01')].shape[0]\n",
    "validator_num_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Festivities<a id='a2'></a>\n",
    "\n",
    "Now lets do a analogues thing for the public holidays. However, instead of setting weights, lets have a two categorical labels:\n",
    "\n",
    "- 1 if day is public holiday\n",
    "- 0 if not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public_holidays = pd.read_csv(base_path+festivities_file_name, encoding = \"ISO-8859-1\", sep = ';', parse_dates = ['Dia'])\n",
    "df_public_holidays = df_public_holidays.loc[df_public_holidays['laborable / festivo / domingo festivo']=='festivo','Dia'].to_frame()\n",
    "df_public_holidays['festivo'] = 1\n",
    "df_public_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing variables\n",
    "\n",
    "validator_num_holidays = df_public_holidays[(df_public_holidays['Dia']<= '2019-09-30') & (df_public_holidays['Dia']>= '2008-01-01')].shape[0]\n",
    "validator_num_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding it all to the transactions dataframe<a id='a3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the file\n",
    "df = pd.read_csv(input_path, sep=sep, parse_dates = ['order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouping by product and date:\n",
    "df = df.groupby(['order_date','product'])['units_ordered'].sum().reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Variables\n",
    "original_shape = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Adding Public holidays<a id='a31'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays = pd.merge(df, df_public_holidays, how = 'left', left_on='order_date', right_on='Dia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays[df_holidays['festivo']==1]['order_date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_holidays['festivo']>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests\n",
    "\n",
    "if df_holidays.shape[0] != original_shape:\n",
    "    test_holiday = (0,\"ERROR - original dataset != holidays dataset\")\n",
    "elif validator_num_holidays != df_holidays.loc[df_holidays['festivo']>0, \"order_date\"].unique().shape[0]:\n",
    "    test_holiday = (0,\"ERROR - holiday numbers != holidays numbers in merged dataset\")\n",
    "else:\n",
    "    test_holiday = (1,\"All good\")\n",
    "print(test_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Adding matches<a id='a32'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_matches = pd.merge(df_holidays, df_matches, how = 'left', left_on='order_date', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_matches = df_holidays_matches[['order_date', 'product', 'units_ordered', 'festivo','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests\n",
    "\n",
    "if df_holidays_matches.shape[0] != original_shape:\n",
    "    test_matches = (0,\"ERROR - original dataset != matches dataset\")\n",
    "elif validator_num_matches != df_holidays_matches.loc[df_holidays_matches['weight']>0, \"order_date\"].unique().shape[0]:\n",
    "    test_matches = (0,\"ERROR - holiday numbers != holidays numbers in merged dataset\")\n",
    "else:\n",
    "    test_matches = (1,\"All good\")\n",
    "print(test_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cleaning NaN created<a id='a4'></a>\n",
    "\n",
    "In this case NaN correspond to 0, so lets replace them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_matches.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tests results & Save to file<a id='a5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test_matches[0] and test_holiday[0]):\n",
    "    print(\"All the tests have been passed. Saving to file\")\n",
    "    df_holidays_matches.to_csv(exit_path, sep=sep, index=False)\n",
    "else:\n",
    "    print(\"Something went wrong, please reviwe errors\")\n",
    "    print(test_matches)\n",
    "    print(test_holiday)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
